{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis: Skills, Experience & Salary\n",
    "\n",
    "## Research Questions\n",
    "1. Which skills correlate most with higher salaries?\n",
    "2. Do certain skill combinations predict higher pay?\n",
    "3. Is experience level the strongest salary predictor?\n",
    "\n",
    "## Methods\n",
    "- Pearson/Spearman correlation\n",
    "- Partial correlation (controlling for experience)\n",
    "- Correlation heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print('✓ Imports complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs: 46,610\n",
      "\n",
      "Columns: ['job_id', 'title', 'company_name', 'location', 'state', 'posted_date_clean', 'year', 'month', 'quarter', 'salary_min', 'salary_max', 'salary_avg', 'has_salary', 'experience_level', 'work_type', 'is_remote', 'skills_text', 'skills_count', 'software_text', 'software_count', 'description', 'source', 'url', 'skills_extracted_text', 'skills_extracted_count']\n"
     ]
    }
   ],
   "source": [
    "# Load data with skills (use the 2025 filtered version with skills and work type)\n",
    "df = pd.read_csv('data/processed/jobs_with_work_type_v2.csv', low_memory=False)\n",
    "\n",
    "print(f\"Total jobs: {len(df):,}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs with salary data: 11,706 (25.1%)\n",
      "\n",
      "Salary range: $9 - $550,000\n",
      "Mean salary: $74,851\n",
      "Median salary: $80,000\n"
     ]
    }
   ],
   "source": [
    "# Filter to jobs with salary data\n",
    "df_salary = df[df['salary_avg'].notna()].copy()\n",
    "\n",
    "print(f\"Jobs with salary data: {len(df_salary):,} ({len(df_salary)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nSalary range: ${df_salary['salary_avg'].min():,.0f} - ${df_salary['salary_avg'].max():,.0f}\")\n",
    "print(f\"Mean salary: ${df_salary['salary_avg'].mean():,.0f}\")\n",
    "print(f\"Median salary: ${df_salary['salary_avg'].median():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs with salary < $100: 3,624\n",
      "\n",
      "Sample values:\n",
      "salary_avg\n",
      "57.5    209\n",
      "30.0    165\n",
      "33.5    135\n",
      "32.5    108\n",
      "15.0    102\n",
      "20.0     99\n",
      "25.0     92\n",
      "60.0     91\n",
      "35.0     88\n",
      "22.5     86\n",
      "55.0     85\n",
      "17.5     80\n",
      "50.0     80\n",
      "12.5     78\n",
      "40.0     76\n",
      "27.5     72\n",
      "37.5     71\n",
      "45.0     70\n",
      "30.5     69\n",
      "65.0     68\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of suspected hourly wages:\n",
      "count    3624.000000\n",
      "mean       40.224161\n",
      "std        19.353863\n",
      "min         9.000000\n",
      "25%        25.000000\n",
      "50%        35.000000\n",
      "75%        55.000000\n",
      "max        99.000000\n",
      "Name: salary_avg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check suspected hourly wages\n",
    "hourly_suspected = df_salary[df_salary['salary_avg'] < 100]\n",
    "\n",
    "print(f\"Jobs with salary < $100: {len(hourly_suspected):,}\")\n",
    "print(f\"\\nSample values:\")\n",
    "print(hourly_suspected['salary_avg'].value_counts().head(20))\n",
    "\n",
    "# Check if they cluster around typical hourly rates ($15-$50/hr)\n",
    "print(f\"\\nDistribution of suspected hourly wages:\")\n",
    "print(hourly_suspected['salary_avg'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Converted 3,624 hourly wages to annual\n",
      "\n",
      "Before conversion:\n",
      "  Min: $9\n",
      "  Mean: $74,851\n",
      "\n",
      "After conversion:\n",
      "  Min: $100\n",
      "  Mean: $100,741\n"
     ]
    }
   ],
   "source": [
    "# Convert hourly to annual (40 hrs/week × 52 weeks = 2080 hrs/year)\n",
    "HOURS_PER_YEAR = 2080\n",
    "HOURLY_THRESHOLD = 100  # Anything under $100 is likely hourly\n",
    "\n",
    "df_salary['salary_converted'] = df_salary['salary_avg'].apply(\n",
    "    lambda x: x * HOURS_PER_YEAR if x < HOURLY_THRESHOLD else x\n",
    ")\n",
    "\n",
    "# Show conversion impact\n",
    "converted_count = (df_salary['salary_avg'] < HOURLY_THRESHOLD).sum()\n",
    "print(f\"✓ Converted {converted_count:,} hourly wages to annual\")\n",
    "\n",
    "print(f\"\\nBefore conversion:\")\n",
    "print(f\"  Min: ${df_salary['salary_avg'].min():,.0f}\")\n",
    "print(f\"  Mean: ${df_salary['salary_avg'].mean():,.0f}\")\n",
    "\n",
    "print(f\"\\nAfter conversion:\")\n",
    "print(f\"  Min: ${df_salary['salary_converted'].min():,.0f}\")\n",
    "print(f\"  Mean: ${df_salary['salary_converted'].mean():,.0f}\")\n",
    "\n",
    "# Use converted salary going forward\n",
    "df_salary['salary_avg'] = df_salary['salary_converted']\n",
    "df_salary = df_salary.drop(columns=['salary_converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SALARY DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      " 1th percentile: $    20,800\n",
      " 5th percentile: $    39,666\n",
      "10th percentile: $    47,840\n",
      "25th percentile: $    68,640\n",
      "50th percentile: $    94,496\n",
      "75th percentile: $   124,800\n",
      "90th percentile: $   160,000\n",
      "95th percentile: $   189,541\n",
      "99th percentile: $   242,229\n",
      "\n",
      "============================================================\n",
      "\n",
      "Jobs with salary < $30k: 267 (2.3%)\n",
      "Jobs with salary > $200k: 447 (3.8%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze salary distribution for outliers\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nSALARY DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    val = df_salary['salary_avg'].quantile(p/100)\n",
    "    print(f\"{p:2}th percentile: ${val:>10,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check extreme values\n",
    "low_outliers = df_salary[df_salary['salary_avg'] < 30000]\n",
    "print(f\"\\nJobs with salary < $30k: {len(low_outliers):,} ({len(low_outliers)/len(df_salary)*100:.1f}%)\")\n",
    "\n",
    "high_outliers = df_salary[df_salary['salary_avg'] > 200000]\n",
    "print(f\"Jobs with salary > $200k: {len(high_outliers):,} ({len(high_outliers)/len(df_salary)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Cleaned to salary range: $30,000 - $200,000\n",
      "✓ Remaining jobs: 10,992\n",
      "✓ New mean: $97,381\n",
      "✓ New median: $93,600\n"
     ]
    }
   ],
   "source": [
    "# Clean salary outliers\n",
    "SALARY_MIN = 30000\n",
    "SALARY_MAX = 200000\n",
    "\n",
    "df_salary = df_salary[\n",
    "    (df_salary['salary_avg'] >= SALARY_MIN) & \n",
    "    (df_salary['salary_avg'] <= SALARY_MAX)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n✓ Cleaned to salary range: ${SALARY_MIN:,} - ${SALARY_MAX:,}\")\n",
    "print(f\"✓ Remaining jobs: {len(df_salary):,}\")\n",
    "print(f\"✓ New mean: ${df_salary['salary_avg'].mean():,.0f}\")\n",
    "print(f\"✓ New median: ${df_salary['salary_avg'].median():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Skill Binary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 unique skills\n",
      "\n",
      "Created 43 skill columns\n",
      "Sample skills: ['a/b testing', 'agile', 'airflow', 'api', 'aws', 'azure', 'bigquery', 'business intelligence', 'data modeling', 'data visualization']\n"
     ]
    }
   ],
   "source": [
    "# Parse skills from skills_extracted_text column\n",
    "def create_skill_columns(df):\n",
    "    \"\"\"Create binary columns for each skill\"\"\"\n",
    "    \n",
    "    # Get all unique skills\n",
    "    all_skills = set()\n",
    "    for skills_text in df['skills_extracted_text'].dropna():\n",
    "        if skills_text:\n",
    "            skills = [s.strip() for s in skills_text.split(',')]\n",
    "            all_skills.update(skills)\n",
    "    \n",
    "    print(f\"Found {len(all_skills)} unique skills\")\n",
    "    \n",
    "    # Create binary columns\n",
    "    for skill in sorted(all_skills):\n",
    "        df[f'skill_{skill}'] = df['skills_extracted_text'].str.contains(\n",
    "            skill, case=False, na=False\n",
    "        ).astype(int)\n",
    "    \n",
    "    return df, sorted(all_skills)\n",
    "\n",
    "df_salary, skills_list = create_skill_columns(df_salary)\n",
    "\n",
    "print(f\"\\nCreated {len(skills_list)} skill columns\")\n",
    "print(f\"Sample skills: {skills_list[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Common Skills:\n",
      "r                              | 3,268 jobs ( 29.7%)\n",
      "sql                            | 2,621 jobs ( 23.8%)\n",
      "business intelligence          | 1,971 jobs ( 17.9%)\n",
      "excel                          | 1,760 jobs ( 16.0%)\n",
      "python                         | 1,554 jobs ( 14.1%)\n",
      "statistics                     | 1,436 jobs ( 13.1%)\n",
      "tableau                        | 1,430 jobs ( 13.0%)\n",
      "power bi                       | 1,306 jobs ( 11.9%)\n",
      "data visualization             | 1,013 jobs (  9.2%)\n",
      "machine learning               |   721 jobs (  6.6%)\n",
      "etl                            |   625 jobs (  5.7%)\n",
      "data warehouse                 |   538 jobs (  4.9%)\n",
      "agile                          |   495 jobs (  4.5%)\n",
      "data modeling                  |   491 jobs (  4.5%)\n",
      "aws                            |   410 jobs (  3.7%)\n",
      "oracle                         |   371 jobs (  3.4%)\n",
      "sas                            |   362 jobs (  3.3%)\n",
      "snowflake                      |   346 jobs (  3.1%)\n",
      "azure                          |   342 jobs (  3.1%)\n",
      "java                           |   277 jobs (  2.5%)\n"
     ]
    }
   ],
   "source": [
    "# Check skill prevalence\n",
    "skill_cols = [f'skill_{s}' for s in skills_list]\n",
    "skill_counts = df_salary[skill_cols].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 Most Common Skills:\")\n",
    "for col, count in skill_counts.head(20).items():\n",
    "    skill_name = col.replace('skill_', '')\n",
    "    pct = (count / len(df_salary)) * 100\n",
    "    print(f\"{skill_name:30} | {count:5,} jobs ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encode Experience Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs with both salary and experience: 0\n",
      "\n",
      "Experience distribution:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Create numeric experience level\n",
    "experience_mapping = {\n",
    "    'Entry Level': 1,\n",
    "    'Mid Level': 2,\n",
    "    'Senior Level': 3,\n",
    "    'Lead': 4,\n",
    "    'Executive': 5,\n",
    "    'Not Specified': np.nan\n",
    "}\n",
    "\n",
    "df_salary['experience_numeric'] = df_salary['experience_level'].map(experience_mapping)\n",
    "\n",
    "# Filter to jobs with experience level\n",
    "df_analysis = df_salary[df_salary['experience_numeric'].notna()].copy()\n",
    "\n",
    "print(f\"Jobs with both salary and experience: {len(df_analysis):,}\")\n",
    "print(f\"\\nExperience distribution:\")\n",
    "print(df_analysis['experience_level'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Skills vs Salary Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation for each skill\n",
    "skill_correlations = []\n",
    "\n",
    "for skill in skills_list:\n",
    "    col = f'skill_{skill}'\n",
    "    \n",
    "    # Only calculate if skill appears in at least 20 jobs\n",
    "    if df_analysis[col].sum() < 20:\n",
    "        continue\n",
    "    \n",
    "    # Pearson correlation\n",
    "    corr, p_value = pearsonr(df_analysis[col], df_analysis['salary_avg'])\n",
    "    \n",
    "    # Mean salary comparison\n",
    "    with_skill = df_analysis[df_analysis[col] == 1]['salary_avg'].mean()\n",
    "    without_skill = df_analysis[df_analysis[col] == 0]['salary_avg'].mean()\n",
    "    salary_diff = with_skill - without_skill\n",
    "    \n",
    "    skill_correlations.append({\n",
    "        'skill': skill,\n",
    "        'correlation': corr,\n",
    "        'p_value': p_value,\n",
    "        'n_jobs': df_analysis[col].sum(),\n",
    "        'mean_salary_with': with_skill,\n",
    "        'mean_salary_without': without_skill,\n",
    "        'salary_premium': salary_diff,\n",
    "        'premium_pct': (salary_diff / without_skill * 100) if without_skill > 0 else 0\n",
    "    })\n",
    "\n",
    "corr_df = pd.DataFrame(skill_correlations).sort_values('correlation', ascending=False)\n",
    "\n",
    "print(f\"\\nAnalyzed {len(corr_df)} skills with 20+ occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top skills positively correlated with salary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 15 SKILLS CORRELATED WITH HIGHER SALARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in corr_df.head(15).iterrows():\n",
    "    sig = \"***\" if row['p_value'] < 0.001 else \"**\" if row['p_value'] < 0.01 else \"*\" if row['p_value'] < 0.05 else \"\"\n",
    "    print(f\"{row['skill']:25} | r={row['correlation']:+.3f}{sig:3} | \"\n",
    "          f\"Premium: ${row['salary_premium']:>7,.0f} ({row['premium_pct']:>+5.1f}%) | \"\n",
    "          f\"{row['n_jobs']:>5,.0f} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottom skills (negative correlation)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SKILLS CORRELATED WITH LOWER SALARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in corr_df.tail(10).iterrows():\n",
    "    sig = \"***\" if row['p_value'] < 0.001 else \"**\" if row['p_value'] < 0.01 else \"*\" if row['p_value'] < 0.05 else \"\"\n",
    "    print(f\"{row['skill']:25} | r={row['correlation']:+.3f}{sig:3} | \"\n",
    "          f\"Penalty: ${row['salary_premium']:>7,.0f} ({row['premium_pct']:>+5.1f}%) | \"\n",
    "          f\"{row['n_jobs']:>5,.0f} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "top_n = 20\n",
    "plot_df = pd.concat([\n",
    "    corr_df.head(top_n//2),\n",
    "    corr_df.tail(top_n//2)\n",
    "]).sort_values('correlation')\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=plot_df['correlation'],\n",
    "    y=plot_df['skill'],\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color=plot_df['correlation'],\n",
    "        colorscale='RdYlGn',\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=\"Correlation\")\n",
    "    ),\n",
    "    text=plot_df['correlation'].apply(lambda x: f'{x:+.3f}'),\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Skills Most/Least Correlated with Salary',\n",
    "    xaxis_title='Correlation Coefficient',\n",
    "    yaxis_title='',\n",
    "    height=600,\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experience Level vs Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience level correlation\n",
    "exp_corr, exp_p = pearsonr(df_analysis['experience_numeric'], df_analysis['salary_avg'])\n",
    "\n",
    "print(f\"\\nExperience Level Correlation with Salary:\")\n",
    "print(f\"Pearson r = {exp_corr:.3f} (p < 0.001)\")\n",
    "print(f\"\\nThis is {'STRONGER' if abs(exp_corr) > corr_df['correlation'].abs().max() else 'WEAKER'} than any individual skill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary by experience level\n",
    "exp_salary = df_analysis.groupby('experience_level')['salary_avg'].agg(['mean', 'median', 'count']).round(0)\n",
    "exp_salary = exp_salary.reindex(['Entry Level', 'Mid Level', 'Senior Level', 'Lead', 'Executive'])\n",
    "\n",
    "print(\"\\nSalary by Experience Level:\")\n",
    "print(\"=\"*60)\n",
    "print(exp_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize experience vs salary\n",
    "fig = px.box(\n",
    "    df_analysis,\n",
    "    x='experience_level',\n",
    "    y='salary_avg',\n",
    "    category_orders={'experience_level': ['Entry Level', 'Mid Level', 'Senior Level', 'Lead', 'Executive']},\n",
    "    title='Salary Distribution by Experience Level',\n",
    "    labels={'salary_avg': 'Average Salary ($)', 'experience_level': 'Experience Level'},\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(color='lightblue'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Partial Correlation (Controlling for Experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate partial correlation for top skills\n",
    "def partial_correlation(x, y, z):\n",
    "    \"\"\"Calculate partial correlation between x and y, controlling for z\"\"\"\n",
    "    r_xy = np.corrcoef(x, y)[0, 1]\n",
    "    r_xz = np.corrcoef(x, z)[0, 1]\n",
    "    r_yz = np.corrcoef(y, z)[0, 1]\n",
    "    \n",
    "    numerator = r_xy - (r_xz * r_yz)\n",
    "    denominator = np.sqrt((1 - r_xz**2) * (1 - r_yz**2))\n",
    "    \n",
    "    return numerator / denominator if denominator != 0 else 0\n",
    "\n",
    "# Calculate for top 20 skills\n",
    "partial_corrs = []\n",
    "\n",
    "for idx, row in corr_df.head(20).iterrows():\n",
    "    skill_col = f'skill_{row[\"skill\"]}'\n",
    "    \n",
    "    # Regular correlation\n",
    "    regular_corr = row['correlation']\n",
    "    \n",
    "    # Partial correlation (controlling for experience)\n",
    "    partial_corr = partial_correlation(\n",
    "        df_analysis[skill_col].values,\n",
    "        df_analysis['salary_avg'].values,\n",
    "        df_analysis['experience_numeric'].values\n",
    "    )\n",
    "    \n",
    "    partial_corrs.append({\n",
    "        'skill': row['skill'],\n",
    "        'regular_correlation': regular_corr,\n",
    "        'partial_correlation': partial_corr,\n",
    "        'difference': regular_corr - partial_corr\n",
    "    })\n",
    "\n",
    "partial_df = pd.DataFrame(partial_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARTIAL CORRELATION (Controlling for Experience Level)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nSkills with INDEPENDENT effect on salary (after controlling for experience):\\n\")\n",
    "\n",
    "for idx, row in partial_df.sort_values('partial_correlation', ascending=False).head(15).iterrows():\n",
    "    print(f\"{row['skill']:25} | \"\n",
    "          f\"Regular: {row['regular_correlation']:+.3f} | \"\n",
    "          f\"Partial: {row['partial_correlation']:+.3f} | \"\n",
    "          f\"Diff: {row['difference']:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Skill Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top skill combinations\n",
    "from itertools import combinations\n",
    "\n",
    "# Get top 10 skills by correlation\n",
    "top_skills = corr_df.head(10)['skill'].tolist()\n",
    "\n",
    "# Analyze 2-skill combinations\n",
    "combo_results = []\n",
    "\n",
    "for skill1, skill2 in combinations(top_skills, 2):\n",
    "    col1 = f'skill_{skill1}'\n",
    "    col2 = f'skill_{skill2}'\n",
    "    \n",
    "    # Jobs with both skills\n",
    "    both = df_analysis[(df_analysis[col1] == 1) & (df_analysis[col2] == 1)]\n",
    "    \n",
    "    if len(both) >= 10:  # At least 10 jobs\n",
    "        # Jobs with only skill1\n",
    "        only1 = df_analysis[(df_analysis[col1] == 1) & (df_analysis[col2] == 0)]\n",
    "        # Jobs with only skill2\n",
    "        only2 = df_analysis[(df_analysis[col1] == 0) & (df_analysis[col2] == 1)]\n",
    "        # Jobs with neither\n",
    "        neither = df_analysis[(df_analysis[col1] == 0) & (df_analysis[col2] == 0)]\n",
    "        \n",
    "        combo_results.append({\n",
    "            'skill1': skill1,\n",
    "            'skill2': skill2,\n",
    "            'n_both': len(both),\n",
    "            'salary_both': both['salary_avg'].mean(),\n",
    "            'salary_only1': only1['salary_avg'].mean() if len(only1) > 0 else 0,\n",
    "            'salary_only2': only2['salary_avg'].mean() if len(only2) > 0 else 0,\n",
    "            'salary_neither': neither['salary_avg'].mean() if len(neither) > 0 else 0\n",
    "        })\n",
    "\n",
    "combo_df = pd.DataFrame(combo_results)\n",
    "combo_df['combo_premium'] = combo_df['salary_both'] - combo_df['salary_neither']\n",
    "combo_df = combo_df.sort_values('salary_both', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 15 SKILL COMBINATIONS BY AVERAGE SALARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in combo_df.head(15).iterrows():\n",
    "    print(f\"{row['skill1']:20} + {row['skill2']:20} | \"\n",
    "          f\"${row['salary_both']:>8,.0f} | \"\n",
    "          f\"+${row['combo_premium']:>7,.0f} premium | \"\n",
    "          f\"{row['n_both']:>4,.0f} jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix for top skills + salary + experience\n",
    "top_20_skills = corr_df.head(20)['skill'].tolist()\n",
    "skill_cols_subset = [f'skill_{s}' for s in top_20_skills]\n",
    "\n",
    "# Select columns for correlation\n",
    "corr_cols = skill_cols_subset + ['experience_numeric', 'salary_avg']\n",
    "corr_matrix = df_analysis[corr_cols].corr()\n",
    "\n",
    "# Rename for readability\n",
    "rename_dict = {f'skill_{s}': s for s in top_20_skills}\n",
    "rename_dict['experience_numeric'] = 'Experience Level'\n",
    "rename_dict['salary_avg'] = 'Salary'\n",
    "corr_matrix = corr_matrix.rename(columns=rename_dict, index=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='RdYlGn',\n",
    "    center=0,\n",
    "    vmin=-0.5,\n",
    "    vmax=0.5,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Correlation Coefficient'}\n",
    ")\n",
    "plt.title('Correlation Heatmap: Top Skills, Experience & Salary', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Heatmap saved to visualizations/correlation_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Strongest predictor\n",
    "top_skill_corr = corr_df.iloc[0]['correlation']\n",
    "print(f\"\\n1. STRONGEST SALARY PREDICTOR:\")\n",
    "print(f\"   Experience Level: r = {exp_corr:.3f}\")\n",
    "print(f\"   Top Skill ({corr_df.iloc[0]['skill']}): r = {top_skill_corr:.3f}\")\n",
    "print(f\"   → Experience is {'STRONGER' if abs(exp_corr) > abs(top_skill_corr) else 'WEAKER'}\")\n",
    "\n",
    "# 2. Top value skills\n",
    "print(f\"\\n2. TOP 5 HIGH-VALUE SKILLS:\")\n",
    "for idx, row in corr_df.head(5).iterrows():\n",
    "    print(f\"   {row['skill']:20} → +${row['salary_premium']:>7,.0f} ({row['premium_pct']:>+5.1f}%)\")\n",
    "\n",
    "# 3. Skills independent of experience\n",
    "print(f\"\\n3. SKILLS WITH INDEPENDENT EFFECT (after controlling for experience):\")\n",
    "for idx, row in partial_df.nlargest(5, 'partial_correlation').iterrows():\n",
    "    print(f\"   {row['skill']:20} → Partial r = {row['partial_correlation']:+.3f}\")\n",
    "\n",
    "# 4. Best skill combo\n",
    "best_combo = combo_df.iloc[0]\n",
    "print(f\"\\n4. HIGHEST-PAYING SKILL COMBINATION:\")\n",
    "print(f\"   {best_combo['skill1']} + {best_combo['skill2']}\")\n",
    "print(f\"   → ${best_combo['salary_both']:,.0f} average salary\")\n",
    "print(f\"   → +${best_combo['combo_premium']:,.0f} premium over no skills\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correlation results\n",
    "corr_df.to_csv('../data/processed/skill_salary_correlations.csv', index=False)\n",
    "combo_df.to_csv('../data/processed/skill_combinations_analysis.csv', index=False)\n",
    "partial_df.to_csv('../data/processed/partial_correlations.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Results exported to data/processed/\")\n",
    "print(\"  - skill_salary_correlations.csv\")\n",
    "print(\"  - skill_combinations_analysis.csv\")\n",
    "print(\"  - partial_correlations.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analyst-job-market-p4YEEnXs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
